[
  {
    "path": "posts/2021-07-20-assignment-mc2/",
    "title": "VAST Challenge 2021: Mini Challenge 2: ",
    "description": "We are asked to analyze movement and tracking data of GAStech employees to identity anomolies and suspicious behaviour.",
    "author": [
      {
        "name": "Hong, Yun Ting",
        "url": "https://www.linkedin.com/in/yuntinghong/"
      }
    ],
    "date": "2021-07-01",
    "categories": [],
    "contents": "\n\nContents\n1. Overview\n2. Literature review of existing analysis performed\n3. Extracting, wrangling and preparing the input data3.1 Setting up environment\n3.2 Importing Employee’s Info and Car Assignment\n3.3 Import Credit card and Loyalty card data\n3.4 Data cleaning\n3.5 Mapping credit cards and loyalty card\n3.6 Importing GPS\n3.7 Car coordinates when vehicle stopped\n3.8 Setting up the map of Abilas, Kronos\n\n4. Insights and ObservationsQuestion 4.1\nQuestion 4.2\nQuestion 4.3\nQuestion 4.4\nQuestion 4.5\n\n\n1. Overview\nGAStech is a company that is located in a country island of Kronos and it has come to their attention that some of the employees had mysteriously went missing. Vehicles tracking data that was secretly installed in the company’s cars and Kronos-Kares benefit card information are delivered to authorities for investigation.\n2. Literature review of existing analysis performed\nVAST challenges: Mini Case 2 was previously attempted back in 2014. There is a slight differences in the data given, such that credit card/Loyalty card records has Employees namein 2014 case and the revised mini case 2 in 2021 was not given any personal information in the card details. Therefore, it requires more cleaning and wrangling of data to infer the owners of the credits cards.\nThere are numerous people who attempted the challenges in 2014 and some are awarded with special honorary segment. However, if we take a look at their reports at VAST challenges Benchmark Repository, most of their work are not reproducible. Most of their designs and charts are either generated using JAVA or SAS enterprise. Therefore, without any code guidance and additional knowledge of coding, it is a steep learning curve in order to reproduce what they presented in their papers.\nOne of the advantage of using R markdown to attempt this challenges is that I have gained certain knowledge in R programming from classes. R studio is a solid platform to reproduce work as code chunks can be written and store in the program and code chunk can be displayed with a simple commend such as echo=TRUE to reflect them when knitting the project.\n3. Extracting, wrangling and preparing the input data\n3.1 Setting up environment\n\n\npackages = c('tidyverse', 'lubridate', 'dplyr', 'raster', 'clock', 'sf', 'tmap', \n             'plotly','ggplot2', 'mapview', 'rgdal','rgeos', 'tidyr', 'move', 'moveVis')\n\nfor (p in packages) {\n  if (!require(p, character.only = T)) {\n    install.packages(p, repos = \"http://cran.us.r-project.org\")\n  }\n  library(p, character.only = T)\n}\n\n\n\n3.2 Importing Employee’s Info and Car Assignment\n\n\ncarAssignment <- read_csv(\"mc2/car-assignments.csv\") \ncarAssignment\n\n\n# A tibble: 44 x 5\n   LastName    FirstName CarID CurrentEmploymentT… CurrentEmploymentT…\n   <chr>       <chr>     <dbl> <chr>               <chr>              \n 1 Calixto     Nils          1 Information Techno… IT Helpdesk        \n 2 Azada       Lars          2 Engineering         Engineer           \n 3 Balas       Felix         3 Engineering         Engineer           \n 4 Barranco    Ingrid        4 Executive           SVP/CFO            \n 5 Baza        Isak          5 Information Techno… IT Technician      \n 6 Bergen      Linnea        6 Information Techno… IT Group Manager   \n 7 Orilla      Elsa          7 Engineering         Drill Technician   \n 8 Alcazar     Lucas         8 Information Techno… IT Technician      \n 9 Cazar       Gustav        9 Engineering         Drill Technician   \n10 Campo-Corr… Ada          10 Executive           SVP/CIO            \n# … with 34 more rows\n\n3.3 Import Credit card and Loyalty card data\n\n\nccData <- read_csv(\"MC2/cc_data.csv\")\nccData$timestamp = date_time_parse(ccData$timestamp, zone = \"\", format = \"%m/%d/%Y %H:%M\")\n\nccData <- ccData %>%\n  mutate(date = as.Date(ymd_hms(timestamp)), time = strftime(timestamp, \"%H:%M\"), hr = strftime(timestamp, \"%H\"))\n\nloyaltyData <- read_csv(\"MC2/loyalty_data.csv\") %>%\n  mutate(date = as.Date(mdy(timestamp)))\n\nccLoyalty <- left_join(ccData, loyaltyData, by = c(\"date\", \"location\", \"price\")) %>%\n  dplyr::select(timestamp.x, date, time, location, price, last4ccnum, loyaltynum, hr) %>%\n  rename(timestamp = timestamp.x) %>%\n  group_by(last4ccnum)\n\nccLoyalty$weekday = wday(ccLoyalty$date, label = TRUE, abbr = TRUE) \nccLoyalty$last4ccnum = as.character(ccLoyalty$last4ccnum)\n\nccLoyalty$location <- gsub(\"[\\x92\\xE2\\x80\\x99]\", \"\", ccLoyalty$location)\nccLoyalty$location <- gsub(\"[\\xfc\\xbe\\x8e\\x96\\x94\\xbc]\", \"e\", ccLoyalty$location)\nccLoyalty\n\n\n# A tibble: 1,496 x 9\n# Groups:   last4ccnum [55]\n   timestamp           date       time  location      price last4ccnum\n   <dttm>              <date>     <chr> <chr>         <dbl> <chr>     \n 1 2014-01-06 07:28:00 2014-01-06 07:28 Brew've Been… 11.3  4795      \n 2 2014-01-06 07:34:00 2014-01-06 07:34 Hallowed Gro… 52.2  7108      \n 3 2014-01-06 07:35:00 2014-01-06 07:35 Brew've Been…  8.33 6816      \n 4 2014-01-06 07:36:00 2014-01-06 07:36 Hallowed Gro… 16.7  9617      \n 5 2014-01-06 07:37:00 2014-01-06 07:37 Brew've Been…  4.24 7384      \n 6 2014-01-06 07:38:00 2014-01-06 07:38 Brew've Been…  4.17 5368      \n 7 2014-01-06 07:42:00 2014-01-06 07:42 Coffee Camel… 28.7  7253      \n 8 2014-01-06 07:43:00 2014-01-06 07:43 Brew've Been…  9.6  4948      \n 9 2014-01-06 07:43:00 2014-01-06 07:43 Brew've Been… 16.9  9683      \n10 2014-01-06 07:47:00 2014-01-06 07:47 Hallowed Gro… 16.5  8129      \n# … with 1,486 more rows, and 3 more variables: loyaltynum <chr>,\n#   hr <chr>, weekday <ord>\n\n3.4 Data cleaning\n\n\nccLoyalty$location <- gsub(\"[\\x92\\xE2\\x80\\x99]\", \"\", ccLoyalty$location)\nccLoyalty$location <- gsub(\"[\\xfc\\xbe\\x8e\\x96\\x94\\xbc]\", \"e\", ccLoyalty$location)\n\nccLoyalty_person <- ccLoyalty %>% \n    group_by(last4ccnum) %>%\n    distinct(loyaltynum) %>%\n    arrange(last4ccnum) %>%\n  filter(loyaltynum != 'NA')\n\nccLoyalty_person$ccPerson <- ccLoyalty_person %>% group_indices(last4ccnum)\n\nlcard <- ccLoyalty %>% \n    group_by(loyaltynum) %>%\n    distinct(last4ccnum) %>%\n    arrange(loyaltynum)\n\nnew <- merge(ccLoyalty_person, lcard, by=\"loyaltynum\") %>%\n  arrange(ccPerson)\n\nlookup <- new %>%\n  select(ccPerson, last4ccnum.y) %>%\n  arrange(ccPerson) %>%\n  distinct(last4ccnum.y, .keep_all = TRUE)\n\nxdata <- inner_join(new, lookup, by=c(\"ccPerson\", \"last4ccnum.y\")) %>%\n  arrange(ccPerson)\n\n# reassign an id to be in running order\nxdata$personId <- xdata %>% group_indices(ccPerson)\n\n\n\n3.5 Mapping credit cards and loyalty card\nA single employee can carries multiple credit cards and loyalty cards\n\n\nccLoyalty_merge <- left_join(ccLoyalty, xdata, by=c(\"last4ccnum\"=\"last4ccnum.y\")) %>%\n  select(personId, timestamp, weekday, timestamp, date, time, location, price, last4ccnum, loyaltynum.x, hr) %>%\n  arrange(personId) %>%\n  distinct()\n \nccLoyalty_merge\n\n\n# A tibble: 1,496 x 10\n# Groups:   last4ccnum [55]\n   personId timestamp           weekday date       time  location     \n      <int> <dttm>              <ord>   <date>     <chr> <chr>        \n 1        1 2014-01-06 08:16:00 Mon     2014-01-06 08:16 Brew've Been…\n 2        1 2014-01-06 12:00:00 Mon     2014-01-06 12:00 Jack's Magic…\n 3        1 2014-01-06 13:27:00 Mon     2014-01-06 13:27 Abila Zacharo\n 4        1 2014-01-06 19:50:00 Mon     2014-01-06 19:50 Frydos Autos…\n 5        1 2014-01-07 07:54:00 Tue     2014-01-07 07:54 Brew've Been…\n 6        1 2014-01-07 12:00:00 Tue     2014-01-07 12:00 Jack's Magic…\n 7        1 2014-01-07 13:24:00 Tue     2014-01-07 13:24 Kalami Kafen…\n 8        1 2014-01-07 20:15:00 Tue     2014-01-07 20:15 Ouzeri Elian \n 9        1 2014-01-08 08:16:00 Wed     2014-01-08 08:16 Brew've Been…\n10        1 2014-01-08 12:00:00 Wed     2014-01-08 12:00 Jack's Magic…\n# … with 1,486 more rows, and 4 more variables: price <dbl>,\n#   last4ccnum <chr>, loyaltynum.x <chr>, hr <chr>\n\n3.6 Importing GPS\nConverting Timestamp to “Year-Month-Day Hour:Minutes” (YYYY-MM-DD HH:MM) format\nSeparate Timestamp into 2 new columns (Date & Time)\nConverting data type for id to factor\n\n\ngps <- read_csv(\"MC2/gps.csv\") %>%\n  mutate(date = as.Date(mdy_hms(Timestamp)), time = format(mdy_hms(Timestamp), \"%H:%M\"))\n\ngps$Timestamp <- date_time_parse(gps$Timestamp, zone = \"\", format = \"%m/%d/%Y %H:%M:%S\")  \ngps$hr <- strftime(gps$Timestamp, \"%H\")\ngps$id <- as_factor(gps$id)\ngps$weekday <- wday(gps$date, label = TRUE, abbr = TRUE) \ngps\n\n\n# A tibble: 685,169 x 8\n   Timestamp           id      lat  long date       time  hr   \n   <dttm>              <fct> <dbl> <dbl> <date>     <chr> <chr>\n 1 2014-01-06 06:28:01 35     36.1  24.9 2014-01-06 06:28 06   \n 2 2014-01-06 06:28:01 35     36.1  24.9 2014-01-06 06:28 06   \n 3 2014-01-06 06:28:03 35     36.1  24.9 2014-01-06 06:28 06   \n 4 2014-01-06 06:28:05 35     36.1  24.9 2014-01-06 06:28 06   \n 5 2014-01-06 06:28:06 35     36.1  24.9 2014-01-06 06:28 06   \n 6 2014-01-06 06:28:07 35     36.1  24.9 2014-01-06 06:28 06   \n 7 2014-01-06 06:28:09 35     36.1  24.9 2014-01-06 06:28 06   \n 8 2014-01-06 06:28:10 35     36.1  24.9 2014-01-06 06:28 06   \n 9 2014-01-06 06:28:11 35     36.1  24.9 2014-01-06 06:28 06   \n10 2014-01-06 06:28:12 35     36.1  24.9 2014-01-06 06:28 06   \n# … with 685,159 more rows, and 1 more variable: weekday <ord>\n\n3.7 Car coordinates when vehicle stopped\nI am eliminating coordinates that indicating that the car is moving The GPS car coordinates are recorded every 1-5 secs. Therefore, if there is a GPS record difference of more than 5 min, which means the employee has driven the car to a destination. Thus this eliminates possible traffic light stops and car moving in motion data.\nFor each employee: 1. I am getting the first and last car coordinate each day 2. Getting places of interest through the day\n\n\nts <- gps %>%\n  group_by(id) %>%\n    arrange(date, time, by_group=TRUE) %>%\n      mutate(diff = round(c(difftime(tail(Timestamp, -1), head(Timestamp, -1), units = \"mins\"), 0)), 2) %>%\n      mutate(count = 1:n(), FIRST = count == 1, LAST = count == max(count)) %>%\n        filter(diff > 5 | FIRST == TRUE | LAST == TRUE) %>%\n  arrange(id) %>%\n  select(id, lat, long, date, time, diff, hr, weekday, Timestamp)\nts\n\n\n# A tibble: 3,133 x 9\n# Groups:   id [40]\n   id      lat  long date       time  diff     hr    weekday\n   <fct> <dbl> <dbl> <date>     <chr> <drtn>   <chr> <ord>  \n 1 1      36.1  24.9 2014-01-06 07:20   0 mins 07    Mon    \n 2 1      36.1  24.9 2014-01-06 07:22  35 mins 07    Mon    \n 3 1      36.0  24.9 2014-01-06 08:04 253 mins 08    Mon    \n 4 1      36.1  24.9 2014-01-06 12:26  59 mins 12    Mon    \n 5 1      36.0  24.9 2014-01-06 13:34 250 mins 13    Mon    \n 6 1      36.1  24.9 2014-01-06 17:48 108 mins 17    Mon    \n 7 1      36.1  24.9 2014-01-06 19:42   7 mins 19    Mon    \n 8 1      36.1  24.9 2014-01-06 19:49  38 mins 19    Mon    \n 9 1      36.1  24.9 2014-01-06 20:33  98 mins 20    Mon    \n10 1      36.0  24.9 2014-01-06 22:15  46 mins 22    Mon    \n# … with 3,123 more rows, and 1 more variable: Timestamp <dttm>\n\n3.8 Setting up the map of Abilas, Kronos\n\nOGR data source with driver: ESRI Shapefile \nSource: \"/Users/yuntinghong/Documents/SMU/ISSS608 - Visual Analytics/hongyunting/YTBlog_ISSS608/_posts/2021-07-20-assignment-mc2/MC2/Geospatial\", layer: \"Abila\"\nwith 3290 features\nIt has 9 fields\nInteger64 fields read as strings:  TLID \n\n4. Insights and Observations\nQuestion 4.1\nUsing just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies?\n\n\n\nObservation\nSupporting Evidence\nFigure 1 shows that “Katerina’s Cafe” is identified as the popular location as it has the highest number of transaction made within these 2 weeks, followed by “Hippokampos” and “Guy’s Gyros”.\n\nFigure 2 shows that “Abila Zacharo” attracts more than 80% of GAStech employees who are entitled a company car.\n\nFigure 3 and 4 indicates that during Monday to Friday (Working day) and between 7am to 8am, the most frequented locations are Food & Beverage outlets, namely “Brew’ve Been Served” where employees go out for lunch or buy a cup of coffee for their breakfast and most of the employees head over “Katerina’s Cafe” at night, probably for dinner.\n\nHowever, based on the credit card and loyalty card record, only 30 employees left at least 1 transaction trail.\n\nAssumptions was made while cleaning credit card and loyalty card transaction. 1 employee carries multiple credit cards and loyalty card.\n\n\n\nccLoyalty_merge$personId <- as_factor(ccLoyalty_merge$personId)\ntest <- ccLoyalty_merge\ntest$date <- as.Date(test$date)\ntest$time <- as.POSIXct(format(test$time, zone=\"\", format = \"%H:%M\"), format = \"%H:%M\")\n\np <-ggplot(test, aes(date, time)) +\n  geom_jitter(aes(group = personId, color = personId)) +\n  scale_y_datetime(date_breaks = \"1 hour\", date_labels = \"%H\") +\n  scale_x_date(date_breaks = \"1 day\", date_labels=\"%d\")\n  \nfig <- ggplotly(p)\n\n\n\n\nThe figure above shows the transactions of all the GAStech employees across these 2 weeks. We can established a pattern of their purchases such as Morning breakfast (7am to 9am), Lunch time at 12pm, late lunch or breaks from 1pm to 3pm and dinner time from 7pm to 10pm.\n There are a few anomalies (outliers) such as the dots from 3am to 6am. Especially during 18 January 2014, 3 transactions are made within 30 mins of each other.\nQuestion 4.2\nAdd the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find? Please limit your answer to 8 images and 500 words.\n\nEach end point of a straight line in Figure X represent that an employee has stopped at a location for a long duration of more than 5 mins over 2 weeks. This shows some of the popular location such as “Brew’ve Been Served”, “Katerina’s Cafe” and “Hallowed Grounds”\nQuestion 4.3\nCan you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data? Please limit your answer to 8 images and 500 words.\nSince we are aware of the popular areas from Question 4.1, these are the locations that is overcrowded with data points. Therefore, the trick to identify the owners to the credit card and loyalty card is by narrowing down the scope to unpopular locations, such as “U-Pump”, “Golf Course” and “Abila Airport”.\nFor Example: 1. There are only 2 transaction made at U-Pump on 2014-01-06; one of them is at 1:18pm, the other is at 5:28pm. Based on the GPS locations on that day, Car 23 and Car 24 had made a stop at U-Pump at 5:12pm for 18 mins and at 12:35 for 47 mins respectively.\n\nThe next location that I used to infer, is “Abila Airport” and I filtered out a single day “2014-01-09”. There are a total of 5 GPS location record at “Abila Aiport” and 4 credit card transactions made.\n3 records of truck ID 104 at 10:51am (For 24 mins), 11:16am (For an hour), 1:09pm (For 2.7 hours)\n1 record of truck ID 101 at 8:29am (For 58 mins)\n1 record of truck ID 106 at 12:37pm (For 41 mins)\nUsing the above vehicles information, I can infer that: - personId 8 in CC data is truck ID 106 - personId 15 in CC data is truck ID 101 - personId 41 in CC data is truck ID 104\n\nHowever, this method may creates loopholes such as if credit card is stolen and used by someone else, it will tend to mislead us that the employee made a purchase but in fact he/she didn’t. The data is missing information on employee personal details with the credit card or loyalty card data. Through data cleaning, we understand that each employee can have multiple credit card and multiple loyalty card, there are bound to be mislinked data.\nQuestion 4.4\nGiven the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. Please limit your response to 8 images and 500 words.\n\n\n\nRelationship\nSupporting Evidence\n1. Car ID 7 and 33 seems to have a romantic relationship. On 8th and 14th, Car ID 7 and 33 checked into Chostus Hotel on a Wednesday brunch hour 11am for a minimum of 1hr 40 mins on both occasions.\n\n2. Car 4 and Car 10 are Golf buddy. On 2 occasions, 12th and 19th, they stopped by Desafio Gold Course at 12:30pm, for 2.5 hours and 1pm, for 3 hours respectively.\n\n3. Engineering team has a after work gathering session on 10th at Car 2 house. Car ID 2,3,5,11,19,18,25,26 and 33 is there.\n\nQuestion 4.5\nDo you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why Please limit your response to 10 images and 500 words.\nSuspicious Activities\nSupport Evidence\n1. On 9th, Truck Driver 107 stop by Abila Hospital and GPS tracking states that he have stopover for at least 17 hours.\n\n2. Car 4 is often seen hanging around courtyard. He has more than 10 GPS records indicating he stop by for long period each time.\n\n3. I believe Car 17, 24, 33 has a certain relationship. They are always staying and leaving from the same location on multiple occasion, with a few mins apart from each other. However, there is no house icon on the maps that indicates it is a residential area.\n\n4. I believe Car ID 14 and 18 had the same behaviour as No.3. They always have stopover GPS records together on multiple occasions\n\n5. Car 24 stopped at Taxiarchon Park on 8th at 11:53pm and stayed for 3 hours. It is weird that someone will head over to a park in the middle of the night\n\n\n\n\n",
    "preview": "posts/2021-07-20-assignment-mc2/assignment-mc2_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-07-25T01:45:04+08:00",
    "input_file": "assignment-mc2.knit.md"
  },
  {
    "path": "posts/2021-06-13-dataviz-makeover-2/",
    "title": "DataViz Makeover 2",
    "description": "SMU ISSS608 DataViz Makeover 2: Exploring different prespective on Merchandise Trade with Partnering Markets",
    "author": [
      {
        "name": "Hong, Yun Ting",
        "url": "https://www.linkedin.com/in/yuntinghong/"
      }
    ],
    "date": "2021-06-13",
    "categories": [],
    "contents": "\n\nContents\n1.0 Critiques on the original design1.1 Clarity\n1.2 Aesthetics\n\n2.0. Alternative Design2.1 Clarity\n2.2 Aesthetics\n\n3.0. Proposed Data Visualization\n4.0. Data Visualisation Step-by-Step4.1. Data Preparation with Excel and Tableau\n4.2 Creating Chart\n\n5.0. Final Visualization5.1. Snapshot of Graph\n5.2. Major Observation and/or derived Insights\n\n\n1.0 Critiques on the original design\nThis is the original design to illustrate Singapore’s Merchandise Trade Performance with Major Partners in 2020 \n1.1 Clarity\n(a) Incomplete axis labelling of both x-axis and y-axis: Although bubble chart label notation indicates ‘Bil’ (which means Billion), we are unclear if x-axis and y-axis are in ‘Bil’ units too as the units are missing from both x-axis and y-axis. Moreover, axis labelling (Import & Export) are placed at the bottom left corner of the chart which can cause confusion as to which axis is Import and Export. This can be improved by placing it at the end of the axis instead.\n(b) Unclear label notation on bubble chart: Each countries are accompanied with a value label notation. However, we will not be able to differentiate whether this value is referring to total merchandise trade value or Net-Net value.\n(c) Missing chart title:  Title is missing from this chart and we are not able to determine what is this chart trying to tell us without looking at Department of Statistics website. We would not have known that this chart is a representation of Singapore Merchandise Trade Performance with majoring Partnering partners in which year or across which years.\n1.2 Aesthetics\n(a) Bubble overlapping: This is a interactive bubble chart as seen in Department of Statistics website. However, at first glance or without interacting with the chart, we are unable to view all the white circles (which indicating whether is it Net-Exporter or Net-Importers). It is hidden by overlapping solid colored bubble. This aesthetic leads to the clarity of the chart.\n(b) No focus area is highlighted: The bubble chart aesthetics are colorful, However, the graph looks cluttered and no focus point. Instead of using solid colors for all partners and introducing additional symbols into the chart with side note, the bubble chart colors should be darker for Taiwan and Hong Kong to bring the focus on this 2 partners and a lighter color for the rest and a small text notation beside Taiwan and Hong Kong to indicate Top Net Importer/Exporter\n(c) Interactive Design does not have much feature:  This chart is an interactive chart, however, if we are looking at multiple years, there is no features to view other years.\n2.0. Alternative Design\n\n2.1 Clarity\n(a) A Short Description in title section:  Write a short description to describe what is kind of information is this chart protraying. For example, is it indicating Net Importer/Exporter or Total Merchandise Trade value.\n(b) Proper Labelling on x and y-axis:  Since the data are revolving around billions unit, it is best to add the unit (B) to x and y axis’s markers.\n(c) Add filter for interactive design:  We are looking at a range of 10 years data, therefore it is best to have a year filter to navigate and see the transition from year to year for a better user experience.\n2.2 Aesthetics\n(a) Introduce opacity to bubble chart: Add opacity level of 20-30% to introduce transparency to bubble chart in case of overlapping points.\n(b) Bubble chart color scheme:  Intead of using different solid colors for different countries as per what DoSS has done, I introduce a red-blue diverging color scheme to different between Net Importer and Net Exporter. For points below the line will be colored closer o dark red and points above the line will be colored close to dark blue.\n(c) Reduce the number of colors and symbols:  As compared to the original graph from DoSS, it is flushed with numerous colors and there is no focus points. In my proposed visualisation, I opted for a simple and clean chart to protray the information. This way, it will not be too cluttered and would not confused the readers.\n3.0. Proposed Data Visualization\nRaw data are available at DoSS, under sub-section of Merchandise Trade by Region/Market.\nActual Data Visualization can be viewed at Tableau Public here\n4.0. Data Visualisation Step-by-Step\n4.1. Data Preparation with Excel and Tableau\nDownload and Open Excelsheet from DoSS\nRemove Unnecessary rows\nRename worksheet T1 to ‘Import’ and T2 to ‘Export’\n\nOne of the partners which we are interested on is European Union. However, the data is in Text format and Billion dollars.\nChange the change from ‘Text’ to ‘Number’\n\nCreate a new row in excel to convert European Union to Thousand Dollars unit. Input the formula (=IF(B7<>“na”, B7 * 1000, “na”)) and apply it to the whole row \nImport the excel data into Tableau \nDrag & Drop “Import” Data Source into the blank space \nProceed to Filter out the 10 Trading Partners (European Union, Hong Kong, Indonesia, Japan, Malaysia, Mainland China, Republic of Korea, Taiwan, Thailand, United States)\nClick on Filter at the top right hand corner \nClick on “Add” to select the variables of which we want to filter the data from \nSelect Variables (Which is essentially our trading partners) and Click OK \nSelect the 10 trading partners (Be mindful to choose “European Union (Thousand Dollars)” instead of “European Union (Million Dollar)”) \nSeparate out trading partner with dollar units\nClick on the little triangle and choose “Custom Split” \nInput “(” in ‘Use the Separator’ \nRename the newly created split column to your intended name by click on the little triangle > Rename \nHide all unused columns\nHold onto “Cntrl” key on the keyboard (“Command” for Mac) and select the year from 1976 Jan to 2010 Dec, 2021 Jan to 2021 May > Click on the little triangle > Hide \nRe-arrange data such that Period are gathered in 1 single column, per country\nHold down on Cntrl key and Select 2011 Jan to 2020 Dec > Click on little triangle > Pivot \nSave the edited data into a CSV file. Click on Sheet 1 at the bottom tab > Right Click on the Data “Import(outputFile)” > Export Data to CSV > Export \nRepeat Step 6 to 11 for “Export” trade Data\nThe next step is to merge both “Import” and “Export” CSV trade data together\nOpen “Export” CSV file, Copy and Paste it to a new worksheet in “Import” CSV file \nSave the CSV file (Final_output.xlsx) as XLSX to save both worksheet into 1 excel file \nImport (Final_output.xlsx) into Tableau \nCombine “Import” and “Export” worksheet into 1 datasource\nDouble click on “Import” and the screen will display “Import is made of 1 table” \nDrag & Drop “Export” next to Import. A venn diagram symbol is created between “Import” and Export\"\n\n4.2 Creating Chart\nNavigate to a new sheet in Tableau.\nCreate new parameters (Total Import and Total Export) Analysis > Create Calculated Field For “Total Import”: SUM([Import Amt]) For “Total Export”: SUM([Export Amt]) \nDrag & Drop “Total Import” to Rows and “Total Export” to Columns \nCreate another Calculated field for Total Merchandise Trade Amount Analysis > Create Calculated Field “Total Trade Amt”: SUM([Import Amt]) + SUM([Export Amt]) \nDrag & Drop “Total Trade Amt” to Size, and click on “Size” and adjust the slider \nCreate another calculated field Analysis > Create Calculated Field “Net Importer”: [Total Import] - Total Export \nDrag & Drop “Net Importer” to Color \nEdit the colors of the bubble plot\nAt the right panel, find “AGG(Net Importer)” and click on the little triangle > Edit Colors \nChoose Red-Blue Diverging \nCheck “Use Full Color Range” and Click OK \nClick on Colors and change teh opacity of the bubble color\n\nBuild Filters for Period\nDrag & Drop Period into Filters \nSelect “Years” and click Next >\n\nSelect all 10 of 10 values and click OK\n\nBuild filter for Country\nDrag & Drop Country into Filter \nSelect all 10 countries and click OK\n\nDisplay the filter Under Filter > Click on little triangle > Show Filter (Do it for YEAR(Period) and Country)\n\nEdit the filter display type\nOn the right panel:\n“Year” - click on little triangle > Single Value (Slider)\n“Country” - Click on little triangle > Multiple Values (List)\n\nRemove “All” from Year Filter.\nClick on little triangle > Customize > Uncheck “Show”All\" Value\"\n\nAdding Reference Line to differentiate Net Importer and Net Exporter\nAnalysis > Create Calculated Field\n\nDrag & Drop “Reference Line” on Rows \nAdjusted the Properties for Reference Line\nDrag & Remove all properties except “Country” in details\nChange from Circle to Line Chart\nChange the Size to the smallest\nChange the color to black\n\nRight click on the line chart > Trend Lines > Show Trend Lines \nOnce you have done the above step correctly, it will look like this \nHowever, if you notice, the diagonal line is not drawing end to end.\nRight click on the axis > Edit Axis\n\nSelect “Fixed” and change the Fixed end to 8.5B\n\nA perfect diagonal line is drawn \nGo to the Row sections > Click on the little triangle > Dual Axis\n\n\nAdjust the trend line properties\nRight Click on the trend line > Format\nGo to “Trend Line” and Select dash line and slimmest line \nHide the Reference Line Header Right Click on Reference Line Axis > Uncheck Show header\n\nCreate another Calculated Field to show Country is Net Importer/Exporter in a particular year\nAnalysis > Create Calculated Field\n“Net Importer/Exporter”: IF[Total Import] > [Total Export] THEN “Net Importer” ELSE “Net Exporter” END\n\nDrag & Drop “Net Importer/Exporter” onto filter Choose all and click OK \nAnnotate Net Importer and Net Exporter onto chart\nRight click on an empty area in the chart > Annotate > Area\n\nDrag & Drop “Country” onto AGG(Total Import) > Label\nClick on Alignment and Select Middle for Vertical Section. This will display country label in the middle of the bubble\n\n5.0. Final Visualization\n5.1. Snapshot of Graph\n\n5.2. Major Observation and/or derived Insights\nBased on the data observed, Hong Kong has been consistently ranked as Singapore Top 1 Net Exporters from Year 2011 to 2020 and Indonesia is ranked Second in Net Exporters from 2011 to 2020 as well. Taiwan has gradually becoming one of Singapore Top Net Importers from 2011 to 2013 and has held Rank 1 for about 5 years before United States took it’s place in Rank 1 for 2 years.\nWhilst, Mainland China has been steadily ranked as the Singapore Top Importer and Exporter throughout the years, with the highest total merchandise trade values of more than $13 billions in the last 10 years, followed by Malaysia of more than $13 billions. Thailand on the other hand has the lowest total merchandise trade values of less than $4 billions.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-20T20:51:24+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-29-dataviz-makeover-1/",
    "title": "DataViz Makeover 1",
    "description": "SMU ISSS608 DataViz Makeover 1: \nData Visualization on Mechandise Trade by Region/Market",
    "author": [
      {
        "name": "Hong, Yun Ting",
        "url": "https://www.linkedin.com/in/yuntinghong/"
      }
    ],
    "date": "2021-05-29",
    "categories": [],
    "contents": "\n\nContents\n1.0 Critiques on the original design1.1 Clarity\n1.2 Aesthetics\n\n2.0. Alternative Design2.1. Advantages of proposed design\n\n3.0. Proposed Data Visualization\n4.0. Data Visualisation Step-by-Step4.1. Data Preparation in Excel\n4.2. Data Visualization in Tableau\n\n5.0. Final Visualization5.1. Snapshot of Graph\n5.2. Major Observation and/or derived Insights\n\n\n1.0 Critiques on the original design\nThis is the original design to illustrate Singapore’s Merchandise Trade with its Top Six Trading Countries from 2019 to 2020\n1.1 Clarity\nNo\nCritiques\nProposed Solution\n1\nTitle can be more informative - The title states what is the data showing, but it did not states what is the data is trying to portray\nCome out with a short description on what should the reader’s be expecting or gaining from the chart\n2\nInconsistent data used - Japan only shows Year 2020 data, whereas the other countries show data from Year 2019 to end of Year 2020\nData should be consistent throughout all countries for a fair comparison\n3\nUsing wrong type of chart - Area line chart is best used when there is at least 1 variable that represent a summation value\nSince ‘Import’ and Export’ are independent variables, I would recommend using line chart if we want to understand the trends.\n1.2 Aesthetics\nNo\nCritiques\nProposed Solution\n1\nNo focus area - There is no annotation or special colored data to indicate point of interest\nHighlight certain data to capture reader’s attention\n2\nX axis markers - X-axis title labeled Month of Period but the markers are only showing years\nShows the markers for months if the axis labeled months\n3\nTransparency of area chart - The opacity of the overlapping area is not prominent for both data to be seen clearly\nIncrease the transparency of ‘Import’ data\n2.0. Alternative Design\n\n2.1. Advantages of proposed design\n2.1.1 Clarity\nTitle tells a better story of what is to be expected from the graph and subtitle is used to annotate the overall chart.\nInstead of raw import and export data, this graph uses of Net Export formula (Export - Import) to illustrate the impact of Import and Export trades.\nAdded units to x axis label to indicate the data is a monetary value.\n2.1.2 Aesthetics\nAesthetically, a simple line chart shows a better trends between the 6 countries.\nColor coordinated, with red indicating negative figures (Trade Deficit) and blue indicating positive figures (Trade Surplus).\nAnnotation is used to highlight key points.\nEach line is accompanied with a country label instead of showing it as a separate legend.\nY axis is not divided into 6 segments, trends can be spotted with the level of granularity for the time period\n3.0. Proposed Data Visualization\nRaw data are available at DoSS, under sub-section of Merchandise Trade by Region/Market.\nActual Data Visualization can be viewed at Tableau Public here\n4.0. Data Visualisation Step-by-Step\n4.1. Data Preparation in Excel\nFilter out the 6 countries (Hong Kong, Mainland China, Japan, Malaysia, Taiwan and United States) from Import Worksheet. \nRetrieve data from Year 2019 Jan to Year 2020 Dec \nRepeat Step 1 and 2 again for Export worksheet\nConsolidate the data into a new worksheet \nTranspose data \nReorganize data into a new worksheet (Data), consisting only 4 columns (Period, Country, Import and Export) \n4.2. Data Visualization in Tableau\nImport the Excel Sheet into Tableau and select “Data” worksheet as Data Source\nChange Data Type\nChange ‘Period’ data type from String to Date\nChange ‘Import’ data type from String to Number (whole)\nChange ‘Export’ data type from String to Number (whole)\nCreate a calculate field to show Net Export\nUnder Analysis > ‘Create Calculated Field’ or Right Click on the left panel > ‘Create Calculated Field’\nInput Calculated Field ‘Net Export (S$)’ Formula:\nSUM([Import]) - SUM([Export])\nCreate a line chart to display Net Export from Year 2019 Jan to Year 2020 Dec\nDrag [Month(Period)] to Columns\nDrag [AGG(Net Export(S$))] to Rows\nSeparating Net Export data into Country level\nDrag [Country] into ‘Details’ and ‘Label’\nAdd colors to differentiate positive or negative net export\nDrag [AGG(Net Export(S$))] to ‘Color’ properties\nFormatting Colors\nOnce Step 5 is done, a color filter interface automatically appear in the right panel\nClick on the down arrow > Edit Colors…\nUnder Palette > Select ‘Red-Blue Diverging’\nCheck ‘Use Full Color Range’\nClick on Advance > Check Center and input 0 as the value\nAdd Annotation\nRight click on an empty space in the chart > Annotate > Area\n5.0. Final Visualization\n5.1. Snapshot of Graph\n\n5.2. Major Observation and/or derived Insights\nThere are 2 extreme trading trends gathered between Taiwan and Hong Kong.\nSingapore trading behavior with Taiwan within this period can assumed to have contributed to Singapore economic growth due to trade surplus. Taiwan main import goods are oil/petroleum and natural gas, in which happen to be Singapore main export goods. Taiwan main export goods are electrical equipment and machinery, however, Singapore are importing it more from other countries such as China, Malaysia and United States. Therefore, Singapore is importing less from Taiwan, and exporting more to Taiwan, creating trade surplus.\nOn the other hand, between 2019 to 2020, Singapore is experiencing trade deficit with Hong Kong. Hong Kong’s main exporting goods are electrical machinery, precious and minerals which Singapore needs. However, Hong Kong’s main imports goods are also machinery equipment which is largely provided by China and Singapore only stands a small percentage of the total export trade. This result in inflow of import goods exceeded the outflow of export goods and this create trade deficit.\nObservatory of Economic Complexity, 2019Singapore Import and Export data, 2019\n\n\n\n",
    "preview": {},
    "last_modified": "2021-07-20T21:14:00+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-22-my-first-post/",
    "title": "My First Post",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Hong, Yun Ting",
        "url": "https://www.linkedin.com/in/yuntinghong/"
      }
    ],
    "date": "2021-05-22",
    "categories": [],
    "contents": "\n1.0 Overview\nIn this article, we will show you how to plot a figure with multiple histograms by using ggplot2 and ggpubr packages.\n2.0 Installing and Launching R Packages\nBefore you get started, you are required:\nto start a new R project, and\nsub-point\n\nto create a new R Markdown document.\nTo insert a graph,\n\nNext, you will use the code chunk below to install and launch ggpubr and tidyverse in RStudio.\nR code\npackages = c(‘ggpubr’, ‘tidyverse’)\nfor(p in packages){library if(!require(p, character.only = T)){ install.packages(p) } library(p, character.only = T) }\n3.0 Importing and Preparing The Data Set\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n3.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\nR code\nwine <- read_csv(“data/wine_quality.csv”)\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type.\n4.0 Univariate EDA with Histogram\nIn the figure below, multiple histograms are plottted by using ggplot() and geom_histogram() of ggplot2 package. Then, ggarrange() of ggpubr package is used to patch these histogram into a single figure to reveal the distribution of the selected variables in the wine quality data sets.\nRcode\nfa <- ggplot(data=wine, aes(x= fixed acidity)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) va <- ggplot(data=wine, aes(x= volatile acidity)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) ca <- ggplot(data=wine, aes(x= citric acid)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) rs <- ggplot(data=wine, aes(x= residual sugar)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) ch <- ggplot(data=wine, aes(x= chlorides)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) fSO2 <- ggplot(data=wine, aes(x= free sulfur dioxide)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) tSO2 <- ggplot(data=wine, aes(x= total sulfur dioxide)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) density <- ggplot(data=wine, aes(x= density)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) pH <- ggplot(data=wine, aes(x= pH)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) sulphates <- ggplot(data=wine, aes(x= sulphates)) + geom_histogram(bins=20, color=“black”, fill=“light blue”) alcohol <- ggplot(data=wine, aes(x= alcohol)) + geom_histogram(bins=20, color=“black”, fill=“light blue”)\nggarrange(fa, va, ca, rs, ch, fSO2, tSO2, density, pH, sulphates, alcohol, ncol = 4, nrow = 3)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-05-30T15:38:29+08:00",
    "input_file": {}
  }
]
